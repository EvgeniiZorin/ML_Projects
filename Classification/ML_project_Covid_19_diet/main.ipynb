{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read & view data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 170\n",
      "Features: ['Country', 'Alcoholic Beverages', 'Animal Products', 'Animal fats', 'Aquatic Products, Other', 'Cereals - Excluding Beer', 'Eggs', 'Fish, Seafood', 'Fruits - Excluding Wine', 'Meat', 'Milk - Excluding Butter', 'Miscellaneous', 'Offals', 'Oilcrops', 'Pulses', 'Spices', 'Starchy Roots', 'Stimulants', 'Sugar Crops', 'Sugar & Sweeteners', 'Treenuts', 'Vegetal Products', 'Vegetable Oils', 'Vegetables', 'Obesity', 'Undernourished', 'Confirmed', 'Deaths', 'Recovered', 'Active', 'Population', 'Unit (all except Population)']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Alcoholic Beverages</th>\n",
       "      <th>Animal Products</th>\n",
       "      <th>Animal fats</th>\n",
       "      <th>Aquatic Products, Other</th>\n",
       "      <th>Cereals - Excluding Beer</th>\n",
       "      <th>Eggs</th>\n",
       "      <th>Fish, Seafood</th>\n",
       "      <th>Fruits - Excluding Wine</th>\n",
       "      <th>Meat</th>\n",
       "      <th>...</th>\n",
       "      <th>Vegetable Oils</th>\n",
       "      <th>Vegetables</th>\n",
       "      <th>Obesity</th>\n",
       "      <th>Undernourished</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Recovered</th>\n",
       "      <th>Active</th>\n",
       "      <th>Population</th>\n",
       "      <th>Unit (all except Population)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>4.7774</td>\n",
       "      <td>0.8504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.1186</td>\n",
       "      <td>0.1501</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.4757</td>\n",
       "      <td>1.2006</td>\n",
       "      <td>...</td>\n",
       "      <td>2.3012</td>\n",
       "      <td>0.7504</td>\n",
       "      <td>4.5</td>\n",
       "      <td>29.8</td>\n",
       "      <td>0.142134</td>\n",
       "      <td>0.006186</td>\n",
       "      <td>0.123374</td>\n",
       "      <td>0.012574</td>\n",
       "      <td>38928000.0</td>\n",
       "      <td>%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>0.9120</td>\n",
       "      <td>16.0930</td>\n",
       "      <td>1.0591</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.2107</td>\n",
       "      <td>0.8091</td>\n",
       "      <td>0.1471</td>\n",
       "      <td>3.8982</td>\n",
       "      <td>3.8688</td>\n",
       "      <td>...</td>\n",
       "      <td>2.8244</td>\n",
       "      <td>2.7508</td>\n",
       "      <td>22.3</td>\n",
       "      <td>6.2</td>\n",
       "      <td>2.967301</td>\n",
       "      <td>0.050951</td>\n",
       "      <td>1.792636</td>\n",
       "      <td>1.123714</td>\n",
       "      <td>2838000.0</td>\n",
       "      <td>%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>0.0896</td>\n",
       "      <td>6.0326</td>\n",
       "      <td>0.1941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0112</td>\n",
       "      <td>0.4181</td>\n",
       "      <td>0.1195</td>\n",
       "      <td>3.1805</td>\n",
       "      <td>1.2543</td>\n",
       "      <td>...</td>\n",
       "      <td>5.7638</td>\n",
       "      <td>2.0457</td>\n",
       "      <td>26.6</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.244897</td>\n",
       "      <td>0.006558</td>\n",
       "      <td>0.167572</td>\n",
       "      <td>0.070767</td>\n",
       "      <td>44357000.0</td>\n",
       "      <td>%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Angola</td>\n",
       "      <td>1.9388</td>\n",
       "      <td>4.6927</td>\n",
       "      <td>0.2644</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.3521</td>\n",
       "      <td>0.0441</td>\n",
       "      <td>0.8372</td>\n",
       "      <td>2.3133</td>\n",
       "      <td>2.9302</td>\n",
       "      <td>...</td>\n",
       "      <td>4.2741</td>\n",
       "      <td>0.3525</td>\n",
       "      <td>6.8</td>\n",
       "      <td>25</td>\n",
       "      <td>0.061687</td>\n",
       "      <td>0.001461</td>\n",
       "      <td>0.056808</td>\n",
       "      <td>0.003419</td>\n",
       "      <td>32522000.0</td>\n",
       "      <td>%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Antigua and Barbuda</td>\n",
       "      <td>2.3041</td>\n",
       "      <td>15.3672</td>\n",
       "      <td>1.5429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.7215</td>\n",
       "      <td>0.2057</td>\n",
       "      <td>1.7280</td>\n",
       "      <td>3.6824</td>\n",
       "      <td>7.0356</td>\n",
       "      <td>...</td>\n",
       "      <td>4.6904</td>\n",
       "      <td>1.2960</td>\n",
       "      <td>19.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.293878</td>\n",
       "      <td>0.007143</td>\n",
       "      <td>0.190816</td>\n",
       "      <td>0.095918</td>\n",
       "      <td>98000.0</td>\n",
       "      <td>%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Country  Alcoholic Beverages  Animal Products  Animal fats  \\\n",
       "0          Afghanistan               0.0000           4.7774       0.8504   \n",
       "1              Albania               0.9120          16.0930       1.0591   \n",
       "2              Algeria               0.0896           6.0326       0.1941   \n",
       "3               Angola               1.9388           4.6927       0.2644   \n",
       "4  Antigua and Barbuda               2.3041          15.3672       1.5429   \n",
       "\n",
       "   Aquatic Products, Other  Cereals - Excluding Beer    Eggs  Fish, Seafood  \\\n",
       "0                      0.0                   37.1186  0.1501         0.0000   \n",
       "1                      0.0                   16.2107  0.8091         0.1471   \n",
       "2                      0.0                   25.0112  0.4181         0.1195   \n",
       "3                      0.0                   18.3521  0.0441         0.8372   \n",
       "4                      0.0                   13.7215  0.2057         1.7280   \n",
       "\n",
       "   Fruits - Excluding Wine    Meat  ...  Vegetable Oils  Vegetables  Obesity  \\\n",
       "0                   1.4757  1.2006  ...          2.3012      0.7504      4.5   \n",
       "1                   3.8982  3.8688  ...          2.8244      2.7508     22.3   \n",
       "2                   3.1805  1.2543  ...          5.7638      2.0457     26.6   \n",
       "3                   2.3133  2.9302  ...          4.2741      0.3525      6.8   \n",
       "4                   3.6824  7.0356  ...          4.6904      1.2960     19.1   \n",
       "\n",
       "   Undernourished  Confirmed    Deaths  Recovered    Active  Population  \\\n",
       "0            29.8   0.142134  0.006186   0.123374  0.012574  38928000.0   \n",
       "1             6.2   2.967301  0.050951   1.792636  1.123714   2838000.0   \n",
       "2             3.9   0.244897  0.006558   0.167572  0.070767  44357000.0   \n",
       "3              25   0.061687  0.001461   0.056808  0.003419  32522000.0   \n",
       "4             NaN   0.293878  0.007143   0.190816  0.095918     98000.0   \n",
       "\n",
       "   Unit (all except Population)  \n",
       "0                             %  \n",
       "1                             %  \n",
       "2                             %  \n",
       "3                             %  \n",
       "4                             %  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('datasets/Food_Supply_kcal_Data.csv')\n",
    "\n",
    "print(f\"Number of rows: {df.shape[0]}\")\n",
    "print(f\"Features: {list(df.columns)}\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with any NaN values: ['Obesity', 'Undernourished', 'Confirmed', 'Deaths', 'Recovered', 'Active']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Obesity           3\n",
       "Undernourished    7\n",
       "Confirmed         6\n",
       "Deaths            6\n",
       "Recovered         6\n",
       "Active            8\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, let's check which columns have any NaN values\n",
    "nan_cols = [i for i in df.columns if df[i].isnull().any()]\n",
    "print(f\"Columns with any NaN values: {nan_cols}\")\n",
    "\n",
    "# Now let's check how many NaN values each of those columns have\n",
    "df[nan_cols].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with any NaN values: []\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], dtype: float64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It is not that many rows with missing values, so let's drop them\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "nan_cols = [i for i in df.columns if df[i].isnull().any()]\n",
    "print(f\"Columns with any NaN values: {nan_cols}\")\n",
    "\n",
    "# Now let's check how many NaN values each of those columns have\n",
    "df[nan_cols].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: save the dataset\n",
    "\n",
    "df.to_csv('datasets/kcal_proc.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features before feature removal:\n",
      "['Country', 'Alcoholic Beverages', 'Animal Products', 'Animal fats', 'Aquatic Products, Other', 'Cereals - Excluding Beer', 'Eggs', 'Fish, Seafood', 'Fruits - Excluding Wine', 'Meat', 'Milk - Excluding Butter', 'Miscellaneous', 'Offals', 'Oilcrops', 'Pulses', 'Spices', 'Starchy Roots', 'Stimulants', 'Sugar Crops', 'Sugar & Sweeteners', 'Treenuts', 'Vegetal Products', 'Vegetable Oils', 'Vegetables', 'Obesity', 'Undernourished', 'Confirmed', 'Deaths', 'Recovered', 'Active', 'Population', 'Unit (all except Population)']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Features after feature removal:\n",
      "['Alcoholic Beverages', 'Cereals - Excluding Beer', 'Eggs', 'Fish, Seafood', 'Fruits - Excluding Wine', 'Meat', 'Milk - Excluding Butter', 'Offals', 'Oilcrops', 'Pulses', 'Spices', 'Starchy Roots', 'Stimulants', 'Sugar Crops', 'Sugar & Sweeteners', 'Treenuts', 'Vegetable Oils', 'Vegetables', 'Deaths']\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Now let's get rid of some features:\n",
    "- Country: irrelevant for classification\n",
    "- Animal Products: too broad\n",
    "\n",
    "\"\"\"\n",
    "print(\"Features before feature removal:\")\n",
    "print(list(df.columns))\n",
    "print('-'*100)\n",
    "\n",
    "df.drop(\n",
    "\tcolumns=['Country', 'Animal Products', 'Animal fats', 'Aquatic Products, Other', \n",
    "\t\t\t'Miscellaneous', 'Obesity', 'Undernourished', 'Confirmed', \n",
    "\t\t\t'Recovered', 'Active', 'Population', 'Unit (all except Population)', 'Vegetal Products'], \n",
    "\tinplace=True)\n",
    "print(\"Features after feature removal:\")\n",
    "print(list(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean death percentage: 0.0399  \n",
      "Median death percentage: 0.0126\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# we can see the distribution of deaths\n",
    "# Perhaps, we can set the median of Deaths as the cut-off point, where\n",
    "# anything below it is low mortality and anything above it is high mortality?\n",
    "mean_deaths = df['Deaths'].mean()\n",
    "median_deaths = df['Deaths'].median()\n",
    "print(f\"Mean death percentage: {mean_deaths:.4f}  \\nMedian death percentage: {median_deaths:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.histplot( data=df, x='Deaths', bins=50 )\n",
    "plt.axvline( median_deaths, color='red', label='median' )\n",
    "plt.axvline( mean_deaths, color='blue', label='mean' )\n",
    "sns.set_context('notebook')\n",
    "plt.legend();\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alcoholic Beverages</th>\n",
       "      <th>Cereals - Excluding Beer</th>\n",
       "      <th>Eggs</th>\n",
       "      <th>Fish, Seafood</th>\n",
       "      <th>Fruits - Excluding Wine</th>\n",
       "      <th>Meat</th>\n",
       "      <th>Milk - Excluding Butter</th>\n",
       "      <th>Offals</th>\n",
       "      <th>Oilcrops</th>\n",
       "      <th>Pulses</th>\n",
       "      <th>Spices</th>\n",
       "      <th>Starchy Roots</th>\n",
       "      <th>Stimulants</th>\n",
       "      <th>Sugar Crops</th>\n",
       "      <th>Sugar &amp; Sweeteners</th>\n",
       "      <th>Treenuts</th>\n",
       "      <th>Vegetable Oils</th>\n",
       "      <th>Vegetables</th>\n",
       "      <th>Deaths_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>37.1186</td>\n",
       "      <td>0.1501</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.4757</td>\n",
       "      <td>1.2006</td>\n",
       "      <td>2.4512</td>\n",
       "      <td>0.1251</td>\n",
       "      <td>0.1751</td>\n",
       "      <td>0.5003</td>\n",
       "      <td>0.1001</td>\n",
       "      <td>0.3252</td>\n",
       "      <td>0.0750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.2261</td>\n",
       "      <td>0.1251</td>\n",
       "      <td>2.3012</td>\n",
       "      <td>0.7504</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9120</td>\n",
       "      <td>16.2107</td>\n",
       "      <td>0.8091</td>\n",
       "      <td>0.1471</td>\n",
       "      <td>3.8982</td>\n",
       "      <td>3.8688</td>\n",
       "      <td>9.9441</td>\n",
       "      <td>0.2648</td>\n",
       "      <td>1.0886</td>\n",
       "      <td>0.8091</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.2651</td>\n",
       "      <td>0.2501</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.4422</td>\n",
       "      <td>0.3972</td>\n",
       "      <td>2.8244</td>\n",
       "      <td>2.7508</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0896</td>\n",
       "      <td>25.0112</td>\n",
       "      <td>0.4181</td>\n",
       "      <td>0.1195</td>\n",
       "      <td>3.1805</td>\n",
       "      <td>1.2543</td>\n",
       "      <td>3.9869</td>\n",
       "      <td>0.0597</td>\n",
       "      <td>0.2688</td>\n",
       "      <td>1.0900</td>\n",
       "      <td>0.1195</td>\n",
       "      <td>1.9262</td>\n",
       "      <td>0.1493</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.9869</td>\n",
       "      <td>0.2240</td>\n",
       "      <td>5.7638</td>\n",
       "      <td>2.0457</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.9388</td>\n",
       "      <td>18.3521</td>\n",
       "      <td>0.0441</td>\n",
       "      <td>0.8372</td>\n",
       "      <td>2.3133</td>\n",
       "      <td>2.9302</td>\n",
       "      <td>0.5067</td>\n",
       "      <td>0.1102</td>\n",
       "      <td>1.0795</td>\n",
       "      <td>1.4981</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>12.6239</td>\n",
       "      <td>0.0441</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.7539</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>4.2741</td>\n",
       "      <td>0.3525</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.4354</td>\n",
       "      <td>16.7927</td>\n",
       "      <td>0.8643</td>\n",
       "      <td>0.2006</td>\n",
       "      <td>1.4663</td>\n",
       "      <td>9.4459</td>\n",
       "      <td>3.1641</td>\n",
       "      <td>0.2624</td>\n",
       "      <td>0.0309</td>\n",
       "      <td>0.1235</td>\n",
       "      <td>0.0309</td>\n",
       "      <td>1.4045</td>\n",
       "      <td>0.2315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0536</td>\n",
       "      <td>0.0463</td>\n",
       "      <td>5.5410</td>\n",
       "      <td>0.8643</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Alcoholic Beverages  Cereals - Excluding Beer    Eggs  Fish, Seafood  \\\n",
       "0               0.0000                   37.1186  0.1501         0.0000   \n",
       "1               0.9120                   16.2107  0.8091         0.1471   \n",
       "2               0.0896                   25.0112  0.4181         0.1195   \n",
       "3               1.9388                   18.3521  0.0441         0.8372   \n",
       "5               1.4354                   16.7927  0.8643         0.2006   \n",
       "\n",
       "   Fruits - Excluding Wine    Meat  Milk - Excluding Butter  Offals  Oilcrops  \\\n",
       "0                   1.4757  1.2006                   2.4512  0.1251    0.1751   \n",
       "1                   3.8982  3.8688                   9.9441  0.2648    1.0886   \n",
       "2                   3.1805  1.2543                   3.9869  0.0597    0.2688   \n",
       "3                   2.3133  2.9302                   0.5067  0.1102    1.0795   \n",
       "5                   1.4663  9.4459                   3.1641  0.2624    0.0309   \n",
       "\n",
       "   Pulses  Spices  Starchy Roots  Stimulants  Sugar Crops  Sugar & Sweeteners  \\\n",
       "0  0.5003  0.1001         0.3252      0.0750          0.0              2.2261   \n",
       "1  0.8091  0.0000         1.2651      0.2501          0.0              3.4422   \n",
       "2  1.0900  0.1195         1.9262      0.1493          0.0              3.9869   \n",
       "3  1.4981  0.0000        12.6239      0.0441          0.0              2.7539   \n",
       "5  0.1235  0.0309         1.4045      0.2315          0.0              7.0536   \n",
       "\n",
       "   Treenuts  Vegetable Oils  Vegetables  Deaths_binary  \n",
       "0    0.1251          2.3012      0.7504              0  \n",
       "1    0.3972          2.8244      2.7508              1  \n",
       "2    0.2240          5.7638      2.0457              0  \n",
       "3    0.0000          4.2741      0.3525              0  \n",
       "5    0.0463          5.5410      0.8643              1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Because the distribution is non-normal, i would suggest using the median\n",
    "df['Deaths_binary'] = df['Deaths'].apply( lambda x: 0 if x < median_deaths else 1 )\n",
    "\n",
    "df.drop(\n",
    "\tcolumns=['Deaths'], \n",
    "\tinplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train (default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For training, we will use 92 features and 92 labels.\n",
      "For validation, we will use 31 features and 31 labels.\n",
      "For testing, we will use 31 features and 31 labels.\n"
     ]
    }
   ],
   "source": [
    "data = df.copy(deep=True)\n",
    "\n",
    "features = data.drop(['Deaths_binary'], axis=1)\n",
    "labels = data['Deaths_binary']\n",
    "\n",
    "# Split the data into test-train-validation sets: 60-20-20%\n",
    "## First split the data into two groups: one with train data, the other - with mixed test and validate\n",
    "features_train, features_validation_test, labels_train, labels_validation_test = train_test_split(\n",
    "\tfeatures, labels, test_size=0.4, random_state=100)\n",
    "## Now, split the test-validate group into the separate test and validate groups\n",
    "features_validation, features_test, labels_validation, labels_test = train_test_split(\n",
    "\tfeatures_validation_test, labels_validation_test, test_size=0.5, random_state=100\n",
    ")\n",
    "print(f\"For training, we will use {len(features_train)} features and {len(labels_train)} labels.\")\n",
    "print(f\"For validation, we will use {len(features_validation)} features and {len(labels_validation)} labels.\")\n",
    "print(f\"For testing, we will use {len(features_test)} features and {len(labels_test)} labels.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\evgen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AdaBoostClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "AdaBoostClassifier()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, let's run the models with the default parameters\n",
    "\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(features_train, labels_train)\n",
    "\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(features_train, labels_train)\n",
    "\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(features_train, labels_train)\n",
    "\n",
    "svm_model = SVC()\n",
    "svm_model.fit(features_train, labels_train)\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(features_train, labels_train)\n",
    "\n",
    "gb_model = GradientBoostingClassifier()\n",
    "gb_model.fit(features_train, labels_train)\n",
    "\n",
    "ab_model = AdaBoostClassifier()\n",
    "ab_model.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Accuracies (high -> low): \n",
      " - Decision Tree: 1.00\n",
      " - Random forest: 1.00\n",
      " - Gradient Boosting: 1.00\n",
      " - AdaBoost: 1.00\n",
      " - Logistic Regression: 0.89\n",
      " - Naive Bayes: 0.84\n",
      " - SVM: 0.76\n"
     ]
    }
   ],
   "source": [
    "# Metric = accuracy\n",
    "\n",
    "accuracy_scores = {}\n",
    "models = [lr_model, dt_model, nb_model, svm_model, rf_model, gb_model, ab_model]\n",
    "model_names = ['Logistic Regression', 'Decision Tree', 'Naive Bayes', 'SVM', 'Random forest', 'Gradient Boosting', 'AdaBoost']\n",
    "\n",
    "for i,j in zip( models, model_names ):\n",
    "\taccuracy_scores[j] = i.score(features_train, labels_train)\n",
    "\n",
    "# Sort the dictionary based on value\n",
    "accuracy_scores2 = dict(sorted(accuracy_scores.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "print('TRAIN Accuracies (high -> low): ')\n",
    "for i in accuracy_scores2:\n",
    "\tprint(f\" - {i}: {accuracy_scores2[i]:.2f}\")\n",
    "\n",
    "# The highest accuracy (81%) is that of gradient boosting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATE accuracies (high -> low): \n",
      " - Naive Bayes: 0.87\n",
      " - SVM: 0.87\n",
      " - Random forest: 0.87\n",
      " - Gradient Boosting: 0.87\n",
      " - AdaBoost: 0.87\n",
      " - Logistic Regression: 0.84\n",
      " - Decision Tree: 0.74\n"
     ]
    }
   ],
   "source": [
    "# VAlidate\n",
    "\n",
    "# Metric = accuracy\n",
    "\n",
    "accuracy_scores = {}\n",
    "models = [lr_model, dt_model, nb_model, svm_model, rf_model, gb_model, ab_model]\n",
    "model_names = ['Logistic Regression', 'Decision Tree', 'Naive Bayes', 'SVM', 'Random forest', 'Gradient Boosting', 'AdaBoost']\n",
    "\n",
    "for i,j in zip( models, model_names ):\n",
    "\taccuracy_scores[j] = i.score(features_validation, labels_validation)\n",
    "\n",
    "# Sort the dictionary based on value\n",
    "accuracy_scores2 = dict(sorted(accuracy_scores.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "print('VALIDATE accuracies (high -> low): ')\n",
    "for i in accuracy_scores2:\n",
    "\tprint(f\" - {i}: {accuracy_scores2[i]:.2f}\")\n",
    "\n",
    "# The highest accuracy (81%) is that of gradient boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train (hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Let's choose the following:\n",
    "- Naive Bayes: to test\n",
    "- Gradient Boosting: to finetune\n",
    "- Random forest: to finetune\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_learning_rate', 'param_max_depth', 'param_min_samples_leaf', 'param_min_samples_split', 'param_n_estimators', 'params', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'split3_test_score', 'split4_test_score', 'mean_test_score', 'std_test_score', 'rank_test_score'])\n",
      "The best estimator is GradientBoostingClassifier(learning_rate=1, max_depth=1, min_samples_leaf=0.1,\n",
      "                           min_samples_split=0.1, n_estimators=50) with parameters {'learning_rate': 1, 'max_depth': 1, 'min_samples_leaf': 0.1, 'min_samples_split': 0.1, 'n_estimators': 50}\n",
      "Train accuracy: 1.0\n",
      "Validation accuracy: 0.7741935483870968\n"
     ]
    }
   ],
   "source": [
    "# Gradient boosting\n",
    "\n",
    "grid_search_parameters = {\n",
    "\t'max_depth': [1,3,5,7,9], \n",
    "\t'learning_rate': [0.01,0.1,1,10,100],\n",
    "\t'n_estimators': [5,50,250,500],\n",
    "\t# 'min_samples_split': np.linspace(0.1, 1.0, 5, endpoint=True),\n",
    "\t'min_samples_split': [0.1,0.4,0.7,1.0], \n",
    "\t# 'min_samples_leaf': np.linspace(0.1, 0.5, 5, endpoint=True)\n",
    "\t'min_samples_leaf': [0.1,0.3,0.5]\n",
    "}\n",
    "\n",
    "gb_tune = GradientBoostingClassifier()\n",
    "gb_tune2 = GridSearchCV(\n",
    "\testimator=gb_tune, \n",
    "\tparam_grid=grid_search_parameters,\n",
    "\trefit=True)\n",
    "gb_tune2.fit(features_train, labels_train)\n",
    "\n",
    "print(gb_tune2.cv_results_.keys())\n",
    "# iter = zip( gb_tune2.cv_results_['mean_train_score'], gb_tune2.cv_results_['mean_test_score']) \n",
    "# for i in iter:\n",
    "# \tprint(i)\n",
    "\n",
    "gb_tune_best = gb_tune2.best_estimator_\n",
    "print(f\"The best estimator is {gb_tune_best} with parameters {gb_tune2.best_params_}\")\n",
    "\n",
    "print(f\"Train accuracy: {gb_tune_best.score(features_train, labels_train)}\")\n",
    "print(f\"Validation accuracy: {gb_tune_best.score(features_validation, labels_validation)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.59574862e-04 4.95962808e-03 1.57181583e-01 2.88556296e-01\n",
      " 1.99388535e-02 5.26321647e-02 0.00000000e+00 0.00000000e+00\n",
      " 1.97919168e-02 2.22821794e-02 4.35353971e-03 9.70882763e-04\n",
      " 3.65657517e-02 0.00000000e+00 3.78049979e-01 3.76410521e-04\n",
      " 1.20286417e-02 2.15259858e-03]\n"
     ]
    }
   ],
   "source": [
    "print(gb_tune_best.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best estimator is RandomForestClassifier(max_depth=10) with parameters {'max_depth': 10, 'min_samples_leaf': 1}\n",
      "Train accuracy: 1.0\n",
      "Validation accuracy: 0.8709677419354839\n"
     ]
    }
   ],
   "source": [
    "# Random forest\n",
    "grid_search_parameters = {\n",
    "\t'max_depth': [1,5,10], \n",
    "\t'min_samples_leaf': [1,5,10,15],\n",
    "}\n",
    "\n",
    "rf_tune = RandomForestClassifier()\n",
    "rf_tune2 = GridSearchCV(\n",
    "\testimator=rf_tune, \n",
    "\tparam_grid=grid_search_parameters,\n",
    "\trefit=True)\n",
    "rf_tune2.fit(features_train, labels_train)\n",
    "\n",
    "# print(rf_tune2.cv_results_.keys())\n",
    "# iter = zip( rf_tune2.cv_results_['mean_train_score'], rf_tune2.cv_results_['mean_test_score']) \n",
    "# for i in iter:\n",
    "# \tprint(i)\n",
    "\n",
    "rf_tune_best = rf_tune2.best_estimator_\n",
    "print(f\"The best estimator is {rf_tune_best} with parameters {rf_tune2.best_params_}\")\n",
    "\n",
    "print(f\"Train accuracy: {rf_tune_best.score(features_train, labels_train)}\")\n",
    "print(f\"Validation accuracy: {rf_tune_best.score(features_validation, labels_validation)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I choose gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.81\n"
     ]
    }
   ],
   "source": [
    "predictions = gb_tune_best.predict( features_test )\n",
    "print(f\"Accuracy: {accuracy_score( labels_test, predictions ):.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier(learning_rate=1, max_depth=1, min_samples_leaf=0.1,\n",
       "                           min_samples_split=0.1, n_estimators=50)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(learning_rate=1, max_depth=1, min_samples_leaf=0.1,\n",
       "                           min_samples_split=0.1, n_estimators=50)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingClassifier(learning_rate=1, max_depth=1, min_samples_leaf=0.1,\n",
       "                           min_samples_split=0.1, n_estimators=50)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(gb_tune_best, \"model.joblib\")\n",
    "\n",
    "loaded_model = joblib.load('model.joblib')\n",
    "loaded_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ddfef2dff3b289ad6149ca203ea5c3e5eaf5f756391d68f0c5d6060d3fe964ec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
